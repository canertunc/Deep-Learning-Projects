{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263331da-9a5d-4596-a214-9dabbf259ea9",
   "metadata": {},
   "source": [
    "**I created a model using a car truck dataset with convolutional neural network.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbf861-a324-4660-8911-22eefe09e8d1",
   "metadata": {},
   "source": [
    "I took data set from kaggle\n",
    "https://www.kaggle.com/datasets/ryanholbrook/car-or-truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce89c79-3860-421a-883d-d40c6bd92d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0164e417-2382-4e71-b028-55e766aa0996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5117 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "for_train = ImageDataGenerator(rescale=1.0/255,shear_range=0.3,zoom_range=0.3,horizontal_flip=True)\n",
    "train_data = for_train.flow_from_directory(\"data_sets/train\",target_size=(64,64),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f29f80-a761-47df-9f24-45bd51d42bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5051 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "for_valid = ImageDataGenerator(rescale=1.0/255)\n",
    "valid_data = for_valid.flow_from_directory(\"data_sets/valid\",target_size=(64,64),batch_size=32,class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a105009-b1b9-47ea-b73f-f82d6e68b801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd157000-315b-4c83-ade7-d0323dbeee61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size=3,activation=\"relu\",input_shape = [64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd7b52f-7b79-4b52-8f6c-852634158f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a804b052-33ed-43de-ae97-6f1340b3453e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size=3,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370950e9-fb03-43ae-9283-405217549f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb500f39-a423-44fc-8c6c-fb0589209196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd86c6a-6b79-4f26-b518-9923c8385f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dfa7fe8-7176-40de-9b35-51568c59fb89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b093e2-07c5-4558-b061-7a8805b95ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b434a1cf-97ab-422e-b8ac-e3b085b09681",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 16s 97ms/step - loss: 0.6522 - accuracy: 0.6103 - val_loss: 0.6104 - val_accuracy: 0.6648\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.6054 - accuracy: 0.6629 - val_loss: 0.5631 - val_accuracy: 0.7151\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.5846 - accuracy: 0.6891 - val_loss: 0.5531 - val_accuracy: 0.7216\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.5475 - accuracy: 0.7244 - val_loss: 0.5205 - val_accuracy: 0.7387\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.5263 - accuracy: 0.7342 - val_loss: 0.4797 - val_accuracy: 0.7743\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.4984 - accuracy: 0.7540 - val_loss: 0.4628 - val_accuracy: 0.7858\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.4731 - accuracy: 0.7837 - val_loss: 0.4874 - val_accuracy: 0.7707\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 13s 82ms/step - loss: 0.4529 - accuracy: 0.7884 - val_loss: 0.4385 - val_accuracy: 0.8014\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.4356 - accuracy: 0.7995 - val_loss: 0.4251 - val_accuracy: 0.8095\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.4198 - accuracy: 0.8040 - val_loss: 0.4428 - val_accuracy: 0.8068\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.4073 - accuracy: 0.8173 - val_loss: 0.4186 - val_accuracy: 0.8062\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3840 - accuracy: 0.8276 - val_loss: 0.4010 - val_accuracy: 0.8238\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3802 - accuracy: 0.8315 - val_loss: 0.4256 - val_accuracy: 0.8204\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3625 - accuracy: 0.8382 - val_loss: 0.3984 - val_accuracy: 0.8204\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 13s 83ms/step - loss: 0.3632 - accuracy: 0.8368 - val_loss: 0.4216 - val_accuracy: 0.8244\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3495 - accuracy: 0.8444 - val_loss: 0.3944 - val_accuracy: 0.8276\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3416 - accuracy: 0.8530 - val_loss: 0.3785 - val_accuracy: 0.8392\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3335 - accuracy: 0.8546 - val_loss: 0.3897 - val_accuracy: 0.8357\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3198 - accuracy: 0.8601 - val_loss: 0.3713 - val_accuracy: 0.8416\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.3266 - accuracy: 0.8601 - val_loss: 0.4058 - val_accuracy: 0.8282\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.3093 - accuracy: 0.8693 - val_loss: 0.3674 - val_accuracy: 0.8474\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2933 - accuracy: 0.8773 - val_loss: 0.3519 - val_accuracy: 0.8511\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2823 - accuracy: 0.8820 - val_loss: 0.3612 - val_accuracy: 0.8491\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2797 - accuracy: 0.8806 - val_loss: 0.3568 - val_accuracy: 0.8523\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2742 - accuracy: 0.8794 - val_loss: 0.3588 - val_accuracy: 0.8481\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.2713 - accuracy: 0.8906 - val_loss: 0.4191 - val_accuracy: 0.8367\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2596 - accuracy: 0.8890 - val_loss: 0.3618 - val_accuracy: 0.8580\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2632 - accuracy: 0.8894 - val_loss: 0.3751 - val_accuracy: 0.8478\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.2432 - accuracy: 0.8954 - val_loss: 0.4686 - val_accuracy: 0.8299\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.2417 - accuracy: 0.8999 - val_loss: 0.3622 - val_accuracy: 0.8588\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2469 - accuracy: 0.8974 - val_loss: 0.3545 - val_accuracy: 0.8577\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2126 - accuracy: 0.9152 - val_loss: 0.3904 - val_accuracy: 0.8531\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.2134 - accuracy: 0.9123 - val_loss: 0.3519 - val_accuracy: 0.8630\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.2023 - accuracy: 0.9195 - val_loss: 0.3740 - val_accuracy: 0.8563\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.1980 - accuracy: 0.9214 - val_loss: 0.3949 - val_accuracy: 0.8573\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.1957 - accuracy: 0.9189 - val_loss: 0.3869 - val_accuracy: 0.8602\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 14s 86ms/step - loss: 0.1967 - accuracy: 0.9216 - val_loss: 0.3745 - val_accuracy: 0.8634\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.1852 - accuracy: 0.9306 - val_loss: 0.4019 - val_accuracy: 0.8543\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.1779 - accuracy: 0.9302 - val_loss: 0.4328 - val_accuracy: 0.8535\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.1695 - accuracy: 0.9312 - val_loss: 0.4547 - val_accuracy: 0.8517\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.1729 - accuracy: 0.9269 - val_loss: 0.3989 - val_accuracy: 0.8668\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.1637 - accuracy: 0.9367 - val_loss: 0.3818 - val_accuracy: 0.8618\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.1622 - accuracy: 0.9398 - val_loss: 0.4161 - val_accuracy: 0.8584\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.1553 - accuracy: 0.9406 - val_loss: 0.4094 - val_accuracy: 0.8602\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.1490 - accuracy: 0.9418 - val_loss: 0.4056 - val_accuracy: 0.8650\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.1449 - accuracy: 0.9402 - val_loss: 0.4033 - val_accuracy: 0.8687\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 13s 84ms/step - loss: 0.1289 - accuracy: 0.9509 - val_loss: 0.5542 - val_accuracy: 0.8565\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.1379 - accuracy: 0.9482 - val_loss: 0.4437 - val_accuracy: 0.8606\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 14s 84ms/step - loss: 0.1356 - accuracy: 0.9439 - val_loss: 0.4737 - val_accuracy: 0.8577\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 14s 85ms/step - loss: 0.1265 - accuracy: 0.9500 - val_loss: 0.4297 - val_accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26cd5bd9030>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = train_data,validation_data=valid_data,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f30fd22-cadd-4872-aecc-4c1a23d86025",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Car': 0, 'Truck': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b302cfb5-159f-41ae-b0db-0b90e2cb8c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Car\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Car\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Truck\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Truck\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "for i in range(1,5):\n",
    "    path = \"data_sets/forTest/carortruck\"+str(i)+\".jpg\"\n",
    "    test_image = load_img(path = path, target_size = (64, 64))\n",
    "    test_image = img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image/255.0)\n",
    "    pred = \"\"\n",
    "    if result[0][0] > 0.5:\n",
    "        pred = \"Truck\"\n",
    "    else:\n",
    "        pred = \"Car\"\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fe327-e606-40f7-9310-3809bc856537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
